{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression with PyTorch\n",
    "\n",
    "In this notebook, I will  explore the MNIST dataset and try to develop a logistic regression model to classify the data via PyTorch.  \n",
    "\n",
    "\n",
    "The MNIST database of handwritten digits, available from this page, has a training set of 60,000 examples, and a test set of 10,000 examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#You might need to run this, if youhave not installed the pytorch before\n",
    "#pip install torchvision \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here are the steps: \n",
    "\n",
    " Step 1. Load Dataset\n",
    " \n",
    " Step 2. Make Dataset Iterable\n",
    " \n",
    " Step 3. Create Model Class\n",
    " \n",
    " Step 4. Instantiate Model Class\n",
    " \n",
    " Step 5. Instantiate Loss Class\n",
    " \n",
    " Step 6. Instantiate Optimizer Class\n",
    " \n",
    " Step 7. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1.1%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "102.8%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2.4%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "112.7%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/mcanbaz/py_39_env/lib/python3.9/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "# lets load the dataset\n",
    "\n",
    "train_dataset = dsets.MNIST(root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_dataset = dsets.MNIST(root='./data', train=False, transform=transforms.ToTensor())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: ./data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: ./data\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(torch.nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = torch.nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = self.linear(x)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "n_iters = 3000\n",
    "epochs = n_iters / (len(train_dataset) / batch_size)\n",
    "input_dim = 784\n",
    "output_dim = 10\n",
    "lr_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(input_dim, output_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss() # computes softmax and then the cross entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500. Loss: 1.3536701202392578. Accuracy: 63.529998779296875.\n",
      "Iteration: 1000. Loss: 1.5278326272964478. Accuracy: 72.86000061035156.\n",
      "Iteration: 1500. Loss: 2.356659412384033. Accuracy: 78.0.\n",
      "Iteration: 2000. Loss: 1.3369340896606445. Accuracy: 80.18000030517578.\n",
      "Iteration: 2500. Loss: 0.6764758825302124. Accuracy: 80.47000122070312.\n",
      "Iteration: 3000. Loss: 1.3610490560531616. Accuracy: 80.83000183105469.\n",
      "Iteration: 3500. Loss: 0.48414960503578186. Accuracy: 80.44000244140625.\n",
      "Iteration: 4000. Loss: 1.146453857421875. Accuracy: 82.97000122070312.\n",
      "Iteration: 4500. Loss: 1.0295732021331787. Accuracy: 84.55999755859375.\n",
      "Iteration: 5000. Loss: 2.2862539291381836. Accuracy: 84.5199966430664.\n",
      "Iteration: 5500. Loss: 0.5406784415245056. Accuracy: 85.05999755859375.\n",
      "Iteration: 6000. Loss: 0.2617846131324768. Accuracy: 85.38999938964844.\n",
      "Iteration: 6500. Loss: 0.5688148736953735. Accuracy: 85.52999877929688.\n",
      "Iteration: 7000. Loss: 0.4263997972011566. Accuracy: 85.70999908447266.\n",
      "Iteration: 7500. Loss: 0.7335862517356873. Accuracy: 86.1500015258789.\n",
      "Iteration: 8000. Loss: 0.11557570844888687. Accuracy: 86.19999694824219.\n",
      "Iteration: 8500. Loss: 0.06827639043331146. Accuracy: 86.83000183105469.\n",
      "Iteration: 9000. Loss: 0.03605823963880539. Accuracy: 86.30999755859375.\n",
      "Iteration: 9500. Loss: 0.19578063488006592. Accuracy: 86.95999908447266.\n",
      "Iteration: 10000. Loss: 0.17149251699447632. Accuracy: 86.98999786376953.\n",
      "Iteration: 10500. Loss: 0.15868660807609558. Accuracy: 87.16000366210938.\n",
      "Iteration: 11000. Loss: 0.6169573068618774. Accuracy: 86.9800033569336.\n",
      "Iteration: 11500. Loss: 0.8277987837791443. Accuracy: 87.22000122070312.\n",
      "Iteration: 12000. Loss: 0.838941216468811. Accuracy: 87.23999786376953.\n",
      "Iteration: 12500. Loss: 2.3986611366271973. Accuracy: 87.70999908447266.\n",
      "Iteration: 13000. Loss: 0.04840300977230072. Accuracy: 87.29000091552734.\n",
      "Iteration: 13500. Loss: 0.20887725055217743. Accuracy: 87.56999969482422.\n",
      "Iteration: 14000. Loss: 0.7309882044792175. Accuracy: 87.81999969482422.\n",
      "Iteration: 14500. Loss: 0.07310518622398376. Accuracy: 87.87000274658203.\n",
      "Iteration: 15000. Loss: 2.6059470176696777. Accuracy: 87.69000244140625.\n",
      "Iteration: 15500. Loss: 0.33484947681427. Accuracy: 87.93000030517578.\n",
      "Iteration: 16000. Loss: 0.5900962948799133. Accuracy: 87.8499984741211.\n",
      "Iteration: 16500. Loss: 0.12935687601566315. Accuracy: 88.22000122070312.\n",
      "Iteration: 17000. Loss: 0.07773983478546143. Accuracy: 88.26000213623047.\n",
      "Iteration: 17500. Loss: 0.20398284494876862. Accuracy: 88.29000091552734.\n",
      "Iteration: 18000. Loss: 0.024397023022174835. Accuracy: 88.0199966430664.\n",
      "Iteration: 18500. Loss: 1.523902416229248. Accuracy: 88.22000122070312.\n",
      "Iteration: 19000. Loss: 0.35393768548965454. Accuracy: 88.66000366210938.\n",
      "Iteration: 19500. Loss: 0.34284481406211853. Accuracy: 88.62000274658203.\n",
      "Iteration: 20000. Loss: 0.9533976912498474. Accuracy: 88.44000244140625.\n",
      "Iteration: 20500. Loss: 0.14013223350048065. Accuracy: 88.58999633789062.\n",
      "Iteration: 21000. Loss: 0.24505874514579773. Accuracy: 88.79000091552734.\n",
      "Iteration: 21500. Loss: 0.9936957955360413. Accuracy: 88.93000030517578.\n",
      "Iteration: 22000. Loss: 0.13776956498622894. Accuracy: 88.86000061035156.\n",
      "Iteration: 22500. Loss: 0.06743139773607254. Accuracy: 88.7699966430664.\n",
      "Iteration: 23000. Loss: 1.501552700996399. Accuracy: 88.52999877929688.\n",
      "Iteration: 23500. Loss: 0.49171870946884155. Accuracy: 88.91000366210938.\n",
      "Iteration: 24000. Loss: 0.5139145255088806. Accuracy: 88.95999908447266.\n",
      "Iteration: 24500. Loss: 0.011946558952331543. Accuracy: 88.63999938964844.\n",
      "Iteration: 25000. Loss: 0.29838377237319946. Accuracy: 88.87999725341797.\n",
      "Iteration: 25500. Loss: 2.338197946548462. Accuracy: 88.9000015258789.\n",
      "Iteration: 26000. Loss: 0.05399519205093384. Accuracy: 88.70999908447266.\n",
      "Iteration: 26500. Loss: 0.1293662041425705. Accuracy: 88.91999816894531.\n",
      "Iteration: 27000. Loss: 0.08062336593866348. Accuracy: 88.95999908447266.\n",
      "Iteration: 27500. Loss: 0.1690255105495453. Accuracy: 89.05000305175781.\n",
      "Iteration: 28000. Loss: 0.3890126645565033. Accuracy: 88.98999786376953.\n",
      "Iteration: 28500. Loss: 0.6162097454071045. Accuracy: 88.98999786376953.\n",
      "Iteration: 29000. Loss: 0.9229382276535034. Accuracy: 88.97000122070312.\n",
      "Iteration: 29500. Loss: 0.6290993094444275. Accuracy: 89.11000061035156.\n",
      "Iteration: 30000. Loss: 0.044214747846126556. Accuracy: 89.05000305175781.\n",
      "Iteration: 30500. Loss: 0.10891610383987427. Accuracy: 89.04000091552734.\n",
      "Iteration: 31000. Loss: 0.08698026090860367. Accuracy: 89.05999755859375.\n",
      "Iteration: 31500. Loss: 0.44692379236221313. Accuracy: 89.12999725341797.\n",
      "Iteration: 32000. Loss: 0.005956517532467842. Accuracy: 89.20999908447266.\n",
      "Iteration: 32500. Loss: 1.0562965869903564. Accuracy: 89.36000061035156.\n",
      "Iteration: 33000. Loss: 0.03374512493610382. Accuracy: 89.30999755859375.\n",
      "Iteration: 33500. Loss: 0.002502645133063197. Accuracy: 89.48999786376953.\n",
      "Iteration: 34000. Loss: 0.3893601596355438. Accuracy: 89.3499984741211.\n",
      "Iteration: 34500. Loss: 0.23199281096458435. Accuracy: 89.4000015258789.\n",
      "Iteration: 35000. Loss: 0.7321041822433472. Accuracy: 89.44999694824219.\n",
      "Iteration: 35500. Loss: 1.7161509990692139. Accuracy: 89.55999755859375.\n",
      "Iteration: 36000. Loss: 6.242803573608398. Accuracy: 89.51000213623047.\n",
      "Iteration: 36500. Loss: 0.7633700370788574. Accuracy: 89.44999694824219.\n",
      "Iteration: 37000. Loss: 0.02324812486767769. Accuracy: 89.4000015258789.\n",
      "Iteration: 37500. Loss: 0.008578591980040073. Accuracy: 89.5.\n",
      "Iteration: 38000. Loss: 0.13702642917633057. Accuracy: 89.51000213623047.\n",
      "Iteration: 38500. Loss: 0.6230328679084778. Accuracy: 89.62000274658203.\n",
      "Iteration: 39000. Loss: 0.3116321265697479. Accuracy: 89.63999938964844.\n",
      "Iteration: 39500. Loss: 1.899998664855957. Accuracy: 89.62999725341797.\n",
      "Iteration: 40000. Loss: 0.23788891732692719. Accuracy: 89.76000213623047.\n",
      "Iteration: 40500. Loss: 0.11640699952840805. Accuracy: 89.79000091552734.\n",
      "Iteration: 41000. Loss: 0.3299720287322998. Accuracy: 89.72000122070312.\n",
      "Iteration: 41500. Loss: 0.03282266855239868. Accuracy: 89.76000213623047.\n",
      "Iteration: 42000. Loss: 2.5873191356658936. Accuracy: 89.95999908447266.\n",
      "Iteration: 42500. Loss: 0.028704732656478882. Accuracy: 89.94999694824219.\n",
      "Iteration: 43000. Loss: 0.03060217946767807. Accuracy: 89.86000061035156.\n",
      "Iteration: 43500. Loss: 0.20600834488868713. Accuracy: 89.97000122070312.\n",
      "Iteration: 44000. Loss: 0.04005948826670647. Accuracy: 89.98999786376953.\n",
      "Iteration: 44500. Loss: 0.00946758408099413. Accuracy: 90.08000183105469.\n",
      "Iteration: 45000. Loss: 0.0348624624311924. Accuracy: 89.94999694824219.\n",
      "Iteration: 45500. Loss: 0.06283369660377502. Accuracy: 89.9000015258789.\n",
      "Iteration: 46000. Loss: 3.7129034996032715. Accuracy: 89.91000366210938.\n",
      "Iteration: 46500. Loss: 0.06705277413129807. Accuracy: 89.94999694824219.\n",
      "Iteration: 47000. Loss: 0.046611327677965164. Accuracy: 89.8499984741211.\n",
      "Iteration: 47500. Loss: 0.06896401941776276. Accuracy: 90.0.\n",
      "Iteration: 48000. Loss: 0.017828799784183502. Accuracy: 89.95999908447266.\n",
      "Iteration: 48500. Loss: 0.0943983793258667. Accuracy: 90.02999877929688.\n",
      "Iteration: 49000. Loss: 0.07096035033464432. Accuracy: 90.22000122070312.\n",
      "Iteration: 49500. Loss: 0.022933142259716988. Accuracy: 89.88999938964844.\n",
      "Iteration: 50000. Loss: 0.1256544440984726. Accuracy: 90.0199966430664.\n",
      "Iteration: 50500. Loss: 0.05368782579898834. Accuracy: 90.11000061035156.\n",
      "Iteration: 51000. Loss: 0.19873391091823578. Accuracy: 90.05999755859375.\n",
      "Iteration: 51500. Loss: 0.020099885761737823. Accuracy: 90.0199966430664.\n",
      "Iteration: 52000. Loss: 0.36093011498451233. Accuracy: 89.93000030517578.\n",
      "Iteration: 52500. Loss: 0.002203776268288493. Accuracy: 90.04000091552734.\n",
      "Iteration: 53000. Loss: 0.017237724736332893. Accuracy: 90.12999725341797.\n",
      "Iteration: 53500. Loss: 4.312360763549805. Accuracy: 89.93000030517578.\n",
      "Iteration: 54000. Loss: 0.07759963721036911. Accuracy: 90.12999725341797.\n",
      "Iteration: 54500. Loss: 1.424173355102539. Accuracy: 90.20999908447266.\n",
      "Iteration: 55000. Loss: 0.18933337926864624. Accuracy: 90.08999633789062.\n",
      "Iteration: 55500. Loss: 0.007700046990066767. Accuracy: 90.13999938964844.\n",
      "Iteration: 56000. Loss: 0.1685115545988083. Accuracy: 90.08999633789062.\n",
      "Iteration: 56500. Loss: 0.01196187175810337. Accuracy: 90.19000244140625.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 57000. Loss: 0.33701372146606445. Accuracy: 90.19999694824219.\n",
      "Iteration: 57500. Loss: 0.11711926758289337. Accuracy: 90.33000183105469.\n",
      "Iteration: 58000. Loss: 0.4243853986263275. Accuracy: 90.33999633789062.\n",
      "Iteration: 58500. Loss: 0.029139718040823936. Accuracy: 90.38999938964844.\n",
      "Iteration: 59000. Loss: 0.11002454906702042. Accuracy: 90.30000305175781.\n",
      "Iteration: 59500. Loss: 0.06259342283010483. Accuracy: 90.33999633789062.\n",
      "Iteration: 60000. Loss: 0.03636601194739342. Accuracy: 90.27999877929688.\n",
      "Iteration: 60500. Loss: 1.1344830989837646. Accuracy: 90.36000061035156.\n",
      "Iteration: 61000. Loss: 0.004178246948868036. Accuracy: 90.33999633789062.\n",
      "Iteration: 61500. Loss: 0.6885717511177063. Accuracy: 90.30000305175781.\n",
      "Iteration: 62000. Loss: 0.00625663623213768. Accuracy: 90.30999755859375.\n",
      "Iteration: 62500. Loss: 0.029521390795707703. Accuracy: 90.33999633789062.\n",
      "Iteration: 63000. Loss: 0.019837552681565285. Accuracy: 90.37000274658203.\n",
      "Iteration: 63500. Loss: 0.018749389797449112. Accuracy: 90.41999816894531.\n",
      "Iteration: 64000. Loss: 0.4639515280723572. Accuracy: 90.31999969482422.\n",
      "Iteration: 64500. Loss: 0.014487904496490955. Accuracy: 90.27999877929688.\n",
      "Iteration: 65000. Loss: 0.0602743923664093. Accuracy: 90.4000015258789.\n",
      "Iteration: 65500. Loss: 0.20203475654125214. Accuracy: 90.4800033569336.\n",
      "Iteration: 66000. Loss: 1.6482174396514893. Accuracy: 90.41000366210938.\n",
      "Iteration: 66500. Loss: 0.046706896275281906. Accuracy: 90.3499984741211.\n",
      "Iteration: 67000. Loss: 1.1958107948303223. Accuracy: 90.47000122070312.\n",
      "Iteration: 67500. Loss: 0.03370317071676254. Accuracy: 90.56999969482422.\n",
      "Iteration: 68000. Loss: 0.0028272203635424376. Accuracy: 90.48999786376953.\n",
      "Iteration: 68500. Loss: 0.32955026626586914. Accuracy: 90.4800033569336.\n",
      "Iteration: 69000. Loss: 0.006684680003672838. Accuracy: 90.44000244140625.\n",
      "Iteration: 69500. Loss: 0.1915973275899887. Accuracy: 90.41999816894531.\n",
      "Iteration: 70000. Loss: 0.026375453919172287. Accuracy: 90.41999816894531.\n",
      "Iteration: 70500. Loss: 0.7774301171302795. Accuracy: 90.54000091552734.\n",
      "Iteration: 71000. Loss: 0.10411781817674637. Accuracy: 90.37999725341797.\n",
      "Iteration: 71500. Loss: 0.08501404523849487. Accuracy: 90.45999908447266.\n",
      "Iteration: 72000. Loss: 2.972533702850342. Accuracy: 90.55999755859375.\n",
      "Iteration: 72500. Loss: 0.042912665754556656. Accuracy: 90.55999755859375.\n",
      "Iteration: 73000. Loss: 0.025932759046554565. Accuracy: 90.58000183105469.\n",
      "Iteration: 73500. Loss: 0.02148333191871643. Accuracy: 90.51000213623047.\n",
      "Iteration: 74000. Loss: 0.022198764607310295. Accuracy: 90.58000183105469.\n",
      "Iteration: 74500. Loss: 0.3904343843460083. Accuracy: 90.4800033569336.\n",
      "Iteration: 75000. Loss: 0.014187660999596119. Accuracy: 90.58000183105469.\n",
      "Iteration: 75500. Loss: 0.455811470746994. Accuracy: 90.55999755859375.\n",
      "Iteration: 76000. Loss: 0.0010744519531726837. Accuracy: 90.63999938964844.\n",
      "Iteration: 76500. Loss: 0.001259368029423058. Accuracy: 90.69000244140625.\n",
      "Iteration: 77000. Loss: 0.0380532331764698. Accuracy: 90.62999725341797.\n",
      "Iteration: 77500. Loss: 0.002283824374899268. Accuracy: 90.52999877929688.\n",
      "Iteration: 78000. Loss: 0.05617983639240265. Accuracy: 90.52999877929688.\n",
      "Iteration: 78500. Loss: 0.09224171191453934. Accuracy: 90.5999984741211.\n",
      "Iteration: 79000. Loss: 0.22459666430950165. Accuracy: 90.58999633789062.\n",
      "Iteration: 79500. Loss: 1.3653833866119385. Accuracy: 90.47000122070312.\n",
      "Iteration: 80000. Loss: 0.00042763148667290807. Accuracy: 90.5.\n",
      "Iteration: 80500. Loss: 0.20904885232448578. Accuracy: 90.51000213623047.\n",
      "Iteration: 81000. Loss: 0.1109403744339943. Accuracy: 90.69000244140625.\n",
      "Iteration: 81500. Loss: 0.017284709960222244. Accuracy: 90.83999633789062.\n",
      "Iteration: 82000. Loss: 0.0035508933942764997. Accuracy: 90.7300033569336.\n",
      "Iteration: 82500. Loss: 0.05777963995933533. Accuracy: 90.69999694824219.\n",
      "Iteration: 83000. Loss: 0.0030343940015882254. Accuracy: 90.72000122070312.\n",
      "Iteration: 83500. Loss: 0.14700964093208313. Accuracy: 90.7300033569336.\n",
      "Iteration: 84000. Loss: 1.3229191303253174. Accuracy: 90.7300033569336.\n",
      "Iteration: 84500. Loss: 0.0033718657214194536. Accuracy: 90.83000183105469.\n",
      "Iteration: 85000. Loss: 0.0016777737764641643. Accuracy: 90.79000091552734.\n",
      "Iteration: 85500. Loss: 0.19521984457969666. Accuracy: 90.87999725341797.\n",
      "Iteration: 86000. Loss: 0.07928747683763504. Accuracy: 90.81999969482422.\n",
      "Iteration: 86500. Loss: 1.3969578742980957. Accuracy: 90.76000213623047.\n",
      "Iteration: 87000. Loss: 0.05290265753865242. Accuracy: 90.83000183105469.\n",
      "Iteration: 87500. Loss: 0.04136528819799423. Accuracy: 90.80000305175781.\n",
      "Iteration: 88000. Loss: 0.7610206604003906. Accuracy: 90.95999908447266.\n",
      "Iteration: 88500. Loss: 0.31656235456466675. Accuracy: 90.81999969482422.\n",
      "Iteration: 89000. Loss: 0.27600958943367004. Accuracy: 90.83000183105469.\n",
      "Iteration: 89500. Loss: 0.12969566881656647. Accuracy: 90.83999633789062.\n",
      "Iteration: 90000. Loss: 0.03068079613149166. Accuracy: 90.83999633789062.\n",
      "Iteration: 90500. Loss: 0.06290724128484726. Accuracy: 90.79000091552734.\n",
      "Iteration: 91000. Loss: 0.13778731226921082. Accuracy: 90.77999877929688.\n",
      "Iteration: 91500. Loss: 1.7217075824737549. Accuracy: 90.8499984741211.\n",
      "Iteration: 92000. Loss: 0.36959847807884216. Accuracy: 90.83000183105469.\n",
      "Iteration: 92500. Loss: 0.24463115632534027. Accuracy: 90.87999725341797.\n",
      "Iteration: 93000. Loss: 0.00420008972287178. Accuracy: 90.97000122070312.\n",
      "Iteration: 93500. Loss: 0.004440566524863243. Accuracy: 90.87999725341797.\n",
      "Iteration: 94000. Loss: 0.07644040137529373. Accuracy: 90.91000366210938.\n",
      "Iteration: 94500. Loss: 0.07488247007131577. Accuracy: 90.79000091552734.\n",
      "Iteration: 95000. Loss: 0.28689706325531006. Accuracy: 90.94000244140625.\n",
      "Iteration: 95500. Loss: 0.002305232686921954. Accuracy: 90.95999908447266.\n",
      "Iteration: 96000. Loss: 0.0739811584353447. Accuracy: 90.93000030517578.\n",
      "Iteration: 96500. Loss: 1.0677428245544434. Accuracy: 90.95999908447266.\n",
      "Iteration: 97000. Loss: 0.19524191319942474. Accuracy: 90.9800033569336.\n",
      "Iteration: 97500. Loss: 0.008574219420552254. Accuracy: 90.9800033569336.\n",
      "Iteration: 98000. Loss: 0.2593725621700287. Accuracy: 90.98999786376953.\n",
      "Iteration: 98500. Loss: 0.29023632407188416. Accuracy: 90.9800033569336.\n",
      "Iteration: 99000. Loss: 0.28639355301856995. Accuracy: 90.9800033569336.\n",
      "Iteration: 99500. Loss: 0.5189657211303711. Accuracy: 91.0.\n",
      "Iteration: 100000. Loss: 0.9697117209434509. Accuracy: 91.0199966430664.\n",
      "Iteration: 100500. Loss: 0.03355344012379646. Accuracy: 91.04000091552734.\n",
      "Iteration: 101000. Loss: 0.8148161768913269. Accuracy: 90.87999725341797.\n",
      "Iteration: 101500. Loss: 0.041972000151872635. Accuracy: 91.05999755859375.\n",
      "Iteration: 102000. Loss: 0.12962928414344788. Accuracy: 90.94000244140625.\n",
      "Iteration: 102500. Loss: 0.2061406672000885. Accuracy: 90.91999816894531.\n",
      "Iteration: 103000. Loss: 0.19334813952445984. Accuracy: 91.06999969482422.\n",
      "Iteration: 103500. Loss: 3.0065531730651855. Accuracy: 90.95999908447266.\n",
      "Iteration: 104000. Loss: 0.4342385530471802. Accuracy: 90.9800033569336.\n",
      "Iteration: 104500. Loss: 0.056769631803035736. Accuracy: 91.1500015258789.\n",
      "Iteration: 105000. Loss: 0.06078673154115677. Accuracy: 91.16000366210938.\n",
      "Iteration: 105500. Loss: 0.05324643477797508. Accuracy: 91.05000305175781.\n",
      "Iteration: 106000. Loss: 0.051607999950647354. Accuracy: 91.02999877929688.\n",
      "Iteration: 106500. Loss: 0.32657259702682495. Accuracy: 91.18000030517578.\n",
      "Iteration: 107000. Loss: 0.008467367850244045. Accuracy: 91.12999725341797.\n",
      "Iteration: 107500. Loss: 0.06913691014051437. Accuracy: 91.22000122070312.\n",
      "Iteration: 108000. Loss: 0.08289748430252075. Accuracy: 91.16999816894531.\n",
      "Iteration: 108500. Loss: 0.21692892909049988. Accuracy: 91.18000030517578.\n",
      "Iteration: 109000. Loss: 1.1979246139526367. Accuracy: 91.16000366210938.\n",
      "Iteration: 109500. Loss: 0.17600905895233154. Accuracy: 91.05999755859375.\n",
      "Iteration: 110000. Loss: 0.027244828641414642. Accuracy: 91.06999969482422.\n",
      "Iteration: 110500. Loss: 0.17149201035499573. Accuracy: 91.0199966430664.\n",
      "Iteration: 111000. Loss: 0.09656663984060287. Accuracy: 91.05000305175781.\n",
      "Iteration: 111500. Loss: 0.46626219153404236. Accuracy: 91.12999725341797.\n",
      "Iteration: 112000. Loss: 0.08095686137676239. Accuracy: 91.12999725341797.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/yq/4bncmmv90_b0nzwlnv5n2nfntwjfnk/T/ipykernel_64184/1435305012.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m                 \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/py_39_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/py_39_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/py_39_env/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/py_39_env/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/py_39_env/lib/python3.9/site-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;31m# doing this so that it is consistent with all other datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# to return a PIL Image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'L'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/py_39_env/lib/python3.9/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   2816\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mversionadded\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1.1\u001b[0m\u001b[0;36m.6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2817\u001b[0m     \"\"\"\n\u001b[0;32m-> 2818\u001b[0;31m     \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__array_interface__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2819\u001b[0m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shape\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2820\u001b[0m     \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "iter = 0\n",
    "\n",
    "for epoch in range(int(epochs)):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = Variable(images.view(-1, 28 * 28))\n",
    "        labels = Variable(labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        iter+=1\n",
    "        if iter%500==0:\n",
    "            # calculate Accuracy\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for images, labels in test_loader:\n",
    "                images = Variable(images.view(-1, 28*28))\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total+= labels.size(0)\n",
    "                # for gpu, bring the predicted and labels back to cpu fro python operations to work\n",
    "                correct+= (predicted == labels).sum()\n",
    "            accuracy = 100 * correct/total\n",
    "            print(\"Iteration: {}. Loss: {}. Accuracy: {}.\".format(iter, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 91.13\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: {0:.2f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_39_env",
   "language": "python",
   "name": "py_39_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
